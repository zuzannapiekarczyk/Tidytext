---
title: "Tidytext"
output: 
  rmdformats::downcute 
date: "06.05.2023"
author: "Joanna Deszcz, Julia Gnatek, Julia Kwapień, Zuzanna Piekarczyk"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

***

**Przydatne linki:**  
https://github.com/dgrtwo/tidy-text-mining/blob/master/index.Rmd  
https://www.tidytextmining.com/tidytext.html  
https://bookdown.org/Maxine/tidy-text-mining/tidy-text-format.html  
https://github.com/rstudio/rmarkdown  

***
***
***  

# Biblioteki
```{r}
#install.packages("rmarkdown")
#install.packages("dplyr")
#install.packages("tidytext")
#install.packages("stringr")
#install.packages("udpipe")
#install.packages("textstem")
#install.packages("tm")
#install.packages("topicmodels")
#install.packages("quanteda")
#install.packages("ggplot2")
#install.packages("tidyr")
#install.packages("stringr")
#install.packages("rmdformats")
```
```{r, include=FALSE}
library(rmarkdown)
library(dplyr)
library(tidytext)
library(stringr)
library(udpipe)
library(textstem)
library(tm)
library(topicmodels)
library(quanteda)
library(ggplot2)
library(tidyr)
library(stringr)
library(rmdformats)
```

***
***
***

# Dane
W projekcie zostały wykorzystane dane z polskimi przysłowiami, które zostały udostępnione w trakcie laboratioriów. Dzięki ponownemu wykorzystaniu znanego zbioru  możliwa będzie lepsza ocena wyników uzyskanych podczas pracy z pakietem **tidytext** w porównaniu z metodami zaprezentowanymi na zajęciach. Dane zawierają 10 rekordów, gdzie każdy rekord to jedno przysłowie.  

***  

## Wczytanie danych
Dane zostały wczytane przy użyciu wektora danych do zmiennej *text*.  
```{r}
text <- c("Jesień tego nie zrodzi, czego wiosna nie zasiała","Czego wiosna nie zasiała – jesień nie urodzi","Św. Bartłomiej pogodny, jesień pogodna","Bartłomiej zwiastuje, jaka jesień następuje, i czy w przyszłym latku dożyjesz dostatku","Bartłomiej zwiastuje, jaka jesień następuje","Bartłomieja cały wrzesień naśladuje, i z nim jesień","Bartłomieja świętego dzień w jakiej zostaje porze, taką jesień bez ochyby daje","Jaki Bartek niesie dzień, taka będzie i jesień","Jaki Bartek niesie dzień, taka będzie i jesień","Jaki Bartek, taki wrzesień, jaki Marcin, taka zima")
```

***

## Czyszczenie tekstu

Funkcja *clean* wykorzystuje biblioteki **stringr** oraz **dplyr**, aby wyczyścić tekst. Wykonuje ona następujące operacje:
  
1. Usuwa podwójne spacje z tekstu.
2. Usuwa znaki kontrolne z tekstu.
3. Zamienia wszystkie litery na małe.
4. Usuwa wszystkie znaki interpunkcyjne.
5. Usuwa ponownie podwójne spacje z tekstu.
6. Usuwa białe znaki z początku i końca tekstu.
  
Wszystkie te operacje służą do usunięcia niepotrzebnych znaków i wyrazów z tekstu, które mogą zakłócać analizę tekstu lub utrudniać jego przetwarzanie. Funkcja zwraca wyczyszczony tekst - zmienna *clean_text*.

```{r}
clean <- function(text){
  
  require(stringr)
  tekst_tenmp <- str_replace_all(text, "\\s{2,}", " ") %>% 
    str_replace_all("[:cntrl:]", " ") %>%
    tolower() %>% 
    str_remove_all("[:punct:]") %>%
    str_remove_all("\\d") %>%
    str_trim()
}
clean_text <- clean(text)
clean_text
```

***

## Stworzenie tabeli zgodnie z ideą tidytext

Kod tworzy dataframe o nazwie *text_df* z dwoma kolumnami: kolumna "line" zawiera numery linii tekstu, natomiast kolumna "text" zawiera wyczyszczony tekst.  

Funkcja *tibble* pochodzi z pakietu **tibble** i jest używana do tworzenia tzw. "tidy data frames", czyli data frame'ów, w których każda kolumna odpowiada jednej zmiennej, a każdy wiersz odpowiada jednej obserwacji. W tym przypadku każda obserwacja to jedna linia tekstu, a każda zmienna to numer linii i tekst.

```{r}
text_df <- tibble(line = 1:length(clean_text), text=clean_text)
text_df
```

***

## Tokenizacja

W kolejnym kroku zostaje wykonana tokenizacja zgodnie z ideą tidytext, czyli podział przysłów na słowa/tokeny. 

Funkcja *unnest_tokens* z biblioteki **tidytext** dzieli tekst na pojedyncze słowa, usuwając jednocześnie wszelkie białe znaki i znaki interpunkcyjne, a następnie umieszcza każde słowo w osobnym wierszu.

Funkcja ta jest przydatna w analizie tekstu, ponieważ umożliwia łatwe zliczanie wystąpień poszczególnych słów i ich analizę. Wynikowy dataframe o nazwie *text_tok* zawiera dwie kolumny: *line*, zawierającą numer linii tekstu, i *word*, zawierającą pojedyncze słowa z tej linii.

```{r}
text_tok <- text_df %>%
  unnest_tokens(word, text)
```

***

## Stopwords

Następnie zostaje stworzona lista "stopwords" (słów-kluczy, które mają zostać usunięte z tekstu), która zostaje przekonwetowana na format *tibble* charakterystyczny dla pakietu *tidytext*. 

Działanie kodu można podzielić na trzy etapy:

1. Utworzenie listy "stopwords" zawierającej słowa, które mają zostać usunięte z tekstu. Lista ta jest utworzona ręcznie i zawiera słowa takie jak "tak", "to", "i", "w" itp., które są bardzo często występującymi słowami i nie niosą dużo znaczenia w kontekście analizy tekstu.
2. Kod używa funkcji **stri_encode** z pakietu *stringi*, aby przekonwertować listę "stopwords" do formatu UTF-8.
3. Ostatecznie kod tworzy *tibble* z kolumną **word**, zawierającą listę słów z listy **stopwords**.

```{r}
stopwords <- c('tak', 'to', 'tego', 'czego', 'jaka', 'taka', 'i', 'czy', 'w', 'z', 'nim', 'jakiej', 'taką', 'jaki', 'takąć', 'takąż', 'taki', 'św')

stopwords <- stringi::stri_encode(stopwords, to = "UTF-8")

stopwords <- tibble(word=stopwords)
```

Po stworzeniu listy stopwords wykorzystana zostaje funkcja *anti_join()* do wyeliminowania stopwords z tekstu. Operacja ta polega na zwróceniu tylko tych wierszy z ramki *text_tok*, dla których nie ma dopasowania z ramką *stopwords* w kolumnie *word*. W tym przypadku chodzi o usunięcie słów, które znajdują się na liście stopwords.

```{r}
text_stop <- anti_join(text_tok, stopwords, by = join_by(word == word))
text_stop
```

***

## Lematyzacja
Lematyzacja to proces sprowadzenia słowa do jego podstawowej formy, zwanej lematem. Celem lematyzacji jest ujednolicenie form słów w tekście, tak aby różne odmiany tego samego słowa były traktowane jako jedno słowo. Lematyzacja jest podobna do stemmingu, ale zamiast obcinania końcówek słów, lematyzacja korzysta z reguł gramatycznych danego języka, aby uzyskać lematy - w tym przypadku reguł języka polskiego.

Powyższy kod wykorzystuje funkcję *lemmatize_words()* z pakietu **polsentiment** do wykonania lematyzacji dla słów w kolumnie *word*. Wynik zostaje zapisany w nowej kolumnie *word_lemma*.

```{r}
text_lem_stem <- text_stop %>%
  mutate(word_lemma = lemmatize_words(word, language = "polish"))
text_lem_stem
```

Niestety jak można zauważyć R nie poradził sobie z lematyzacją w j. polskim i słowa pozostały w niezmienionej formie. Dlatego też zdecydowano się na dokonanie lematyzacji w oparciu o słownik wykorzystywany podczas zajęć.

W pierwszym kroku wczytany został uproszczony słownik z pliku *slownik.txt* do zmiennej *dictionary*. Dane przekształcono na typ tibble w celu zachowania spójności z pakietem **tidytext**. Dodatkowo dokonany zmiany nazwy drugiej kolumny na *word*.

Wykorzystano pakiet **dplyr** oraz funkcję *left_join()*, która po dopasowaniu zmiennej *word* w dataframe'ie *text_stop* ze wzorcem *word* w dataframe'ie *dictionary* zamieniała wartość na wzorzec z kolumny *V1*.

```{r}
dictionary <- read.csv2("slownik.txt", header=F, fileEncoding = "")

dictionary <- as_tibble(dictionary, rownames = NULL)

dictionary<- rename(dictionary, word = V2)

text_lem <- text_stop %>%
  left_join(dictionary, by = c("word" = "word")) %>%
  mutate(word = if_else(!is.na(V1), V1, word))
text_lem <- text_lem %>% select(line, word)
text_lem
```
***

### Przygotowanie tabeli document-term

Ostatnim elementem etapu przygotowania danych było zliczenie ilości wystąpień poszczególnych termów w obrębie danego przysłowia przy użyciu funkcji *count()* z pakietu **dplyr**. W rezultacie powstał obiekt tibble o wymiarach 53x3. W nomenklaturze tidytext obiekt ten można nazwać tabelą *document-term*, która posłuży do stworzenia m.in. *macierzy document-term* w kolejnych etapach projektu.

```{r}
text_lem <- text_lem %>%
  select(line,word) %>%
  count(line, word) %>%
  rename(count = n, word = word)
text_lem
```
Tak przekształcone dane były gotowe do przeprowadzenia zaplanowanych analiz.

***
***
***

# Macierz document-term DTM
```{r}
dtm <- text_lem %>% 
  cast_dtm(document = line, term = word, value = count)
dtm
```

# Macierz document-feature DFM
```{r}
dfm <- text_lem %>% 
  cast_dfm(document = line, term = word, value = count)
dfm
```


# Macierz document-term DTM
```{r}
dtm_sparse <- text_lem %>% 
  cast_sparse(line, word, count)
dtm_sparse
```

# Macierz feature-document
```{r}
fdm <- t(as.matrix(dtm))
fdm
```

# Binarna
```{r}
binary_fdm <- apply(fdm, MARGIN = c(1,2), FUN = function(x) ifelse(x > 0, 1, 0))
binary_fdm
```
W wyniku tej sekwencji kodu, zmienna binary_fdm będzie zawierała macierz binarną, w której każdy element będzie przyjmował wartość 1, jeśli odpowiadający mu element w macierzy FDM jest większy niż 0, a w przeciwnym przypadku będzie miał wartość 0. 



# Logarytmiczna
```{r}
log_fdm <- log(fdm + 1) # dodanie 1 do wszystkich elementów przed obliczeniem logarytmu
log_fdm
```
Aby przekształcić macierz FDM (Frequency Document Matrix) na macierz logarytmiczną, można wykorzystać funkcję log() w języku R. Ponieważ logarytm naturalny nie jest zdefiniowany dla wartości zero, w przypadku wystąpienia wartości zero w macierzy FDM można dodać małą wartość stałą do wszystkich elementów przed obliczeniem logarytmu. 


### TF - wyszukanie termów które różnicuja dany dokument w kontekscie innych dokumentów
```{r}
tf_matrix <- t(apply(fdm, 1, function(x) x/sum(x)))
tf_matrix
```
Aby przekształcić macierz FDM (Frequency Document Matrix) na macierz TF (Term Frequency), należy podzielić każdy element macierzy przez sumę elementów w danym wierszu, czyli przez liczbę wszystkich wystąpień w danym dokumencie.
W wyniku tej sekwencji kodu, zmienna tf_matrix będzie zawierała macierz TF, w której każdy element będzie wynikiem podzielenia odpowiadającego mu elementu w macierzy FDM przez sumę elementów w danym wierszu. Ta operacja pozwala na uzyskanie liczby wystąpień danego słowa (termu) w dokumencie, znormalizowanej przez liczbę wszystkich słów w dokumencie.


### TF-IDF usuwa termy, które są chcarakterstyczne dla wszystkich dokumentów i zostawia tylko te unikalne/różnicujące
```{r}
tf_matrix <- t(apply(fdm, 1, function(x) x/sum(x))) # macierz TF
idf_weights <- log(nrow(fdm)/rowSums(fdm > 0)) # wektor wag IDF
tfidf_matrix <- tf_matrix * idf_weights # macierz TF-IDF
tfidf_matrix
```
Aby przekształcić macierz FDM (Frequency Document Matrix) na macierz TF-IDF (Term Frequency-Inverse Document Frequency), należy pomnożyć każdy element macierzy TF przez wagę IDF dla danego termu, która wyraża się wzorem idf(t) = log(N/df(t)), gdzie N to liczba wszystkich dokumentów, a df(t) to liczba dokumentów zawierających term t. 

W wyniku tej sekwencji kodu, zmienna tfidf_matrix będzie zawierała macierz TF-IDF, w której każdy element będzie wynikiem pomnożenia odpowiadającego mu elementu w macierzy TF przez wagę IDF dla danego termu. Ta operacja pozwala na wyodrębnienie najistotniejszych słów (termów) w danym dokumencie, ponieważ słowa występujące często w jednym dokumencie, ale rzadko w innych, będą miały wyższą wagę TF-IDF.
